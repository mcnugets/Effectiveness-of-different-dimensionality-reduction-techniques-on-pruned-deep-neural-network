{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different DR technique (ICA) on saved neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\sulta\\anaconda3\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\sulta\\anaconda3\\lib\\site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn as sk\n",
    "from sklearn import decomposition as dec\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=5)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading saved network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=12, kernel_size=(5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=12, out_channels=16, kernel_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = nn.Softmax(dim=0)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()\n",
    "# model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = iter(testloader)\n",
    "images_test, labels_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "the_output = model(images_test)\n",
    "\n",
    "acc, lb_pred = torch.max(the_output, 1)\n",
    "print(lb_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs_normal = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs_normal.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\n",
    "    f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 400)\n"
     ]
    }
   ],
   "source": [
    "fc1_w = model.fc1.weight.detach().numpy()\n",
    "fc2_w = model.fc2.weight.detach().numpy()\n",
    "fc3_w = model.fc3.weight.detach().numpy()\n",
    "\n",
    "\n",
    "print(fc1_w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fc1_ICA = dec.FastICA(n_components=60,\n",
    "            whiten='unit-variance')\n",
    "\n",
    "fc1_reduced = fc1_ICA.fit_transform(fc1_w.T)\n",
    "fc1_reduced  = torch.tensor(fc1_reduced.T ,dtype=torch.float)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 60)\n"
     ]
    }
   ],
   "source": [
    "fc2_ICA = dec.FastICA(n_components=60,\n",
    "            whiten='unit-variance')\n",
    "fc2_reduced = fc2_ICA.fit_transform(fc2_w)\n",
    "print(fc2_reduced.shape)\n",
    "\n",
    "fc2_ICA2 = dec.FastICA(n_components=42, whiten='unit-variance')\n",
    "fc2_reduced = fc2_ICA2.fit_transform(fc2_reduced.T)\n",
    "fc2_reduced = torch.tensor(fc2_reduced.T,  dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 42])\n"
     ]
    }
   ],
   "source": [
    "fc3_w = model.fc3.weight.detach().numpy()\n",
    "fc3_w = fc3_w.reshape(fc3_w.shape[0] * 2, -1)\n",
    "fc3_ICA = dec.FastICA(n_components=10, whiten='unit-variance', max_iter=300)\n",
    "fc3_reduced = fc3_ICA.fit_transform(fc3_w.T)\n",
    "fc3_reduced = torch.tensor(fc3_reduced.T, dtype=torch.float)\n",
    "print(fc3_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 400])\n",
      "torch.Size([42, 60])\n",
      "torch.Size([10, 42])\n"
     ]
    }
   ],
   "source": [
    "print(fc1_reduced.shape)\n",
    "print(fc2_reduced.shape)\n",
    "print(fc3_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1 = nn.Linear(400, 60, bias=True)\n",
    "model.fc2 = nn.Linear(60,42,bias=True)\n",
    "model.fc3 = nn.Linear(42,10, bias=True)\n",
    "\n",
    "model.fc1.weight = nn.Parameter(fc1_reduced)\n",
    "model.fc2.weight = nn.Parameter(fc2_reduced)\n",
    "model.fc3.weight = nn.Parameter(fc3_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6445, 6.9086, 0.7945, 5.2515], grad_fn=<MaxBackward0>)\n",
      "tensor([3, 8, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "the_output = model(images_test)\n",
    "\n",
    "acc, lb_pred = torch.max(the_output, 1)\n",
    "print(acc)\n",
    "print(lb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs_normal = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs_normal.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\n",
    "    f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302 acc: 13.425\n",
      "[1,  4000] loss: 2.301 acc: 17.375\n",
      "[1,  6000] loss: 2.266 acc: 19.525\n",
      "[1,  8000] loss: 2.171 acc: 22.225\n",
      "[1, 10000] loss: 2.132 acc: 25.688\n",
      "[1, 12000] loss: 2.102 acc: 27.875\n",
      "epoch: 1\n",
      "[2,  2000] loss: 2.591 acc: 30.630\n",
      "[2,  4000] loss: 2.057 acc: 32.000\n",
      "[2,  6000] loss: 2.049 acc: 31.587\n",
      "[2,  8000] loss: 2.042 acc: 33.450\n",
      "[2, 10000] loss: 2.036 acc: 34.175\n",
      "[2, 12000] loss: 2.027 acc: 34.600\n",
      "epoch: 2\n",
      "[3,  2000] loss: 2.522 acc: 35.050\n",
      "[3,  4000] loss: 2.024 acc: 35.400\n",
      "[3,  6000] loss: 2.008 acc: 36.425\n",
      "[3,  8000] loss: 2.015 acc: 36.725\n",
      "[3, 10000] loss: 2.009 acc: 36.900\n",
      "[3, 12000] loss: 2.002 acc: 37.737\n",
      "epoch: 3\n",
      "[4,  2000] loss: 2.500 acc: 38.230\n",
      "[4,  4000] loss: 1.993 acc: 38.250\n",
      "[4,  6000] loss: 1.990 acc: 39.663\n",
      "[4,  8000] loss: 1.986 acc: 40.337\n",
      "[4, 10000] loss: 1.989 acc: 39.913\n",
      "[4, 12000] loss: 1.984 acc: 39.837\n",
      "epoch: 4\n",
      "[5,  2000] loss: 2.474 acc: 41.140\n",
      "[5,  4000] loss: 1.969 acc: 42.525\n",
      "[5,  6000] loss: 1.970 acc: 41.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sulta\\Jupyter NoteBooks\\NN optimization individual project\\custom_nn_ICA.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m profile(activities\u001b[39m=\u001b[39m[ProfilerActivity\u001b[39m.\u001b[39mCPU, ProfilerActivity\u001b[39m.\u001b[39mCUDA]) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m      outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\sulta\\Jupyter NoteBooks\\NN optimization individual project\\custom_nn_ICA.ipynb Cell 21\u001b[0m in \u001b[0;36mNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)  \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/NN%20optimization%20individual%20project/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mc:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(optimizer)\n",
    "\n",
    "running_loss = 0.0\n",
    "total = 0.0\n",
    "correct = 0.0\n",
    "loss_nodr =[]\n",
    "acc_nodr = []\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    print('epoch:', epoch)\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad(True)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "             outputs = model(inputs).to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            loss_temp = running_loss / 2000\n",
    "            acc_temp = 100 * correct / total\n",
    "            loss_nodr.append(loss_temp)\n",
    "            acc_nodr.append(acc_temp)\n",
    "            print(\n",
    "                f'[{epoch + 1}, {i + 1:5d}] loss: {loss_temp:.3f} acc: {acc_temp:.3f}')\n",
    "            running_loss = 0.0\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = './model_ICA_reduced.pt'\n",
    "torch.save(model.state_dict, path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the capacity of the model after applying FastICA onto the weights matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes of data sample:  cat\n",
      "classes of data sample:  ship\n",
      "classes of data sample:  ship\n",
      "classes of data sample:  plane\n"
     ]
    }
   ],
   "source": [
    "data_sample, labels = iter(testloader).next()\n",
    "\n",
    "for l in labels:\n",
    "    print('classes of data sample: ', classes[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0106, -0.0324,  0.0332, -0.0228, -0.1344, -0.0133,  0.0336,  0.1185,\n",
      "         0.1332, -0.1631, -0.1097,  0.1063, -0.1316, -0.0879, -0.0189,  0.0023,\n",
      "        -0.1091, -0.0054, -0.0687, -0.2570, -0.1722,  0.0175,  0.0333,  0.0006,\n",
      "         0.1241,  0.0555,  0.1032, -0.0437,  0.2082, -0.0532, -0.0901, -0.2231,\n",
      "         0.0722, -0.0443,  0.3296,  0.0758, -0.3826,  0.0570,  0.0889,  0.1991,\n",
      "         0.1702, -0.0960,  0.0980, -0.2003, -0.1400,  0.0505, -0.1144,  0.0542,\n",
      "         0.0348,  0.2222,  0.0564, -0.0176,  0.2313,  0.0844, -0.1637,  0.1060,\n",
      "        -0.1245,  0.0091,  0.0931,  0.0072], requires_grad=True)\n",
      "(60, 1)\n",
      "net bias updated: torch.Size([60])\n",
      "(42, 1)\n",
      "net bias updated: torch.Size([42])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(model.fc1.bias)\n",
    "bias_n = model.fc1.bias\n",
    "bias_n = bias_n.detach().numpy()\n",
    "bias_n = bias_n.reshape(60, -1)\n",
    "print(bias_n.shape)\n",
    "\n",
    "bias_transformer = dec.FastICA(n_components=1,\n",
    "            random_state=0,\n",
    "            whiten='unit-variance',\n",
    "            tol=2,\n",
    "            max_iter=500)\n",
    "aa = bias_transformer.fit_transform(bias_n)\n",
    "aa = aa.flatten()\n",
    "model.fc1.bias = nn.Parameter(torch.tensor(aa, dtype=torch.float))\n",
    "print('net bias updated:', model.fc1.bias.shape)\n",
    "\n",
    "\n",
    "bias_n = model.fc2.bias\n",
    "bias_n = bias_n.detach().numpy()\n",
    "bias_n = bias_n.reshape(42, -1)\n",
    "print(bias_n.shape)\n",
    "\n",
    "bias_transformer = dec.FastICA(n_components=1,\n",
    "            random_state=0,\n",
    "            whiten='unit-variance',\n",
    "            tol=2,\n",
    "            max_iter=500)\n",
    "aa = bias_transformer.fit_transform(bias_n)\n",
    "aa = aa.flatten()\n",
    "model.fc2.bias = nn.Parameter(torch.tensor(aa, dtype=torch.float))\n",
    "print('net bias updated:', model.fc2.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "tensor([3, 6, 7, 3])\n",
      "predicted classes:  cat\n",
      "predicted classes:  frog\n",
      "predicted classes:  horse\n",
      "predicted classes:  cat\n"
     ]
    }
   ],
   "source": [
    "result = model(data_sample)\n",
    "print(result.shape)\n",
    "\n",
    "acc, lb_prediction  =  torch.max(result, 1)\n",
    "print(lb_prediction)\n",
    "\n",
    "for lb in lb_prediction:\n",
    "    print('predicted classes: ', classes[lb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f8eb618b7b569c23d3b4b5bc22124c155d58b9880b777276332025b24a4c4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
