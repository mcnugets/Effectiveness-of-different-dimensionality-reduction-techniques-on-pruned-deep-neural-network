{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different DR technique (ICA) on saved neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\sulta\\anaconda3\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\sulta\\anaconda3\\lib\\site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn as sk\n",
    "from sklearn import decomposition as dec\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune\n",
    "import sklearn.manifold as nonlin\n",
    "import copy\n",
    "import pickle as pk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "#cifar10\n",
    "trainset_cifar = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset_cifar, validset_cifar = torch.utils.data.random_split(trainset_cifar, [45000,5000])\n",
    "\n",
    "\n",
    "\n",
    "trainloader_cifar = torch.utils.data.DataLoader(trainset_cifar, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "validloader_cifar = torch.utils.data.DataLoader(validset_cifar, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset_cifar = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader_cifar = torch.utils.data.DataLoader(testset_cifar, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes_cifar = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "# MNIST DATASET\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "mnist_train, mnist_valid = torch.utils.data.random_split(mnist_train, [50000,10000])\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader_mnist = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n",
    "                                                shuffle=True, num_workers=2)\n",
    "validloader_mnist =  torch.utils.data.DataLoader(mnist_valid, batch_size=batch_size,\n",
    "                                                shuffle=True, num_workers=2)                                          \n",
    "testloader_mnist = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
    "                                               shuffle=True, num_workers=2)\n",
    "classes_mnist =  ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_sample = iter(testloader_mnist)\n",
    "sample_im, sample_lbl = next(mnist_dataset_sample)\n",
    "\n",
    "cifar_dataset_sample = iter(testloader_cifar)\n",
    "sample_im_c, sample_lbl_c = next(cifar_dataset_sample)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary functions to perform dimensional reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_weights(model,weights):\n",
    "    w1,w2,w3 = weights\n",
    "    model.fc1.weight.data = w1\n",
    "    model.fc2.weight.data = w2\n",
    "    model.fc3.weight.data = w3\n",
    "    return model\n",
    "\n",
    "\n",
    "def construct_model(model, layers):\n",
    "    l1, l2, l3 = layers\n",
    "    model.fc1 = l1\n",
    "    model.fc2 = l2\n",
    "    model.fc3 = l3\n",
    "    return model\n",
    "    \n",
    "def change_dimensionality(weight, dr_method):\n",
    "    x1 = weight.detach().numpy().T\n",
    "    x1 = dr_method.fit_transform(x1)\n",
    "    x1 = torch.tensor(x1.T, dtype=torch.float32)\n",
    "    print(\"x_new vector\")\n",
    "    print(x1.shape)\n",
    "    return x1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drprojection(model, method, whiten):\n",
    "    weight_list = []\n",
    "    weight1 = model.fc1.weight\n",
    "    print('fc1 layer weight')\n",
    "\n",
    "    fc1_reduced = change_dimensionality(\n",
    "        weight1, method(n_components=int(weight1.shape[0]/2),  whiten=whiten, random_state=0, tol= 10))\n",
    "    weight_list.append(fc1_reduced)\n",
    "    x2 = torch.mm(model.fc1.weight, fc1_reduced.T)\n",
    "    print(x2.shape)\n",
    "    weight2 = torch.mm(model.fc2.weight, x2)\n",
    "    print(weight2.shape)\n",
    "\n",
    "    fc2_reduced = change_dimensionality(\n",
    "        weight2, method(n_components=int(weight2.shape[0]/2),whiten=whiten, random_state=0, tol= 10))\n",
    "    print('fc2 layer weight')\n",
    "    print(fc2_reduced.shape)\n",
    "    weight_list.append(fc2_reduced)\n",
    "\n",
    "    x3_reduced = torch.mm(weight2, fc2_reduced.T)\n",
    "\n",
    "    fc3_reduced = torch.mm(model.fc3.weight, x3_reduced)\n",
    "    print('fc3 layer weight')\n",
    "    print(fc3_reduced.shape)\n",
    "    weight_list.append(fc3_reduced)\n",
    "\n",
    "    return weight_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_accuracy(net, dataset):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\n",
    "        f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def every_class_accuracy(model, testloader, classes):\n",
    "    cor_pred = {classname: 0 for classname in classes}\n",
    "    t_pred = {classname: 0 for classname in classes}\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            im, labels = data\n",
    "            output = model(im)\n",
    "            _, predictions = torch.max(output, dim=1)\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    cor_pred[classes[label]] += 1\n",
    "                t_pred[classes[label]] += 1\n",
    "    \n",
    "    for classname, correct_count in cor_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / t_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def training(model, trainset,valset, n, filename):\n",
    "    device = torch.device('cuda:0')\n",
    "    running_loss = 0.0\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    loss_nodr = []\n",
    "    acc_nodr = []\n",
    "    \n",
    "    val_loss_nodr = []\n",
    "    model = model.to(device)\n",
    "    val_acc_nodr = []\n",
    "  \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    print(optimizer)\n",
    "\n",
    "    for epoch in range(n):\n",
    "\n",
    "        print('epoch:', epoch)\n",
    "        for i, data in enumerate(trainset):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad(True)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "                 \n",
    "                 outputs = model(inputs).to(device)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val=0.0\n",
    "        correct_val = 0.0\n",
    "\n",
    "        for i, data in enumerate(valset):\n",
    "\n",
    "            inputs, labels2 = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels2 = labels2.to(device)\n",
    "            val_output  = model(inputs).to(device)\n",
    "            loss = criterion(val_output, labels2)\n",
    "            val_loss+=loss.item()\n",
    "            total_val+=labels2.size(0)\n",
    "            _, pred = torch.max(val_output.data, 1)\n",
    "            correct_val += (pred == labels2).sum().item()\n",
    "\n",
    "            \n",
    "            \n",
    "        train_loss = running_loss/len(trainset)\n",
    "        acc_temp = 100 * correct / total\n",
    "\n",
    "        valid_loss_temp = val_loss/len(valset)\n",
    "        valid_acc_temp = (100 * correct_val)/total_val\n",
    "        loss_nodr.append(train_loss)\n",
    "        acc_nodr.append(acc_temp)\n",
    "\n",
    "        val_loss_nodr.append(valid_loss_temp)\n",
    "        val_acc_nodr.append(valid_acc_temp)\n",
    "        print(\n",
    "            f'[{epoch + 1}, {i + 1:5d}] train loss: {train_loss:.3f} train acc: {acc_temp:.3f}', \n",
    "            f'valid acc: {valid_acc_temp:.3f} valid loss  {valid_loss_temp:.3f} ')\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    pickle_accloss(acc_nodr, loss_nodr,val_acc_nodr,val_loss_nodr,  filename)\n",
    "\n",
    "    \n",
    "def pickle_accloss(acc, loss,valid_acc, valid_loss, filename):\n",
    "    accandloss = {'accuracy' : acc, 'loss' : loss, 'valid acc' : valid_acc, 'valid loss': valid_loss}\n",
    "    with open('./data_vis/ICA/{}.pickle'.format(filename), 'wb') as ica_acc_and_loss:\n",
    "        pk.dump(accandloss, ica_acc_and_loss)\n",
    "    print('Saved dictionary of loss and accuracy!')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional reduction with the dataset MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved network/Initializing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, is_normalize):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=12, kernel_size=(5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=12, out_channels=16, kernel_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(256, 120) # 256x 60\n",
    "        self.fc2 = nn.Linear(120, 84) # 60 x 84\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.soft = nn.Softmax(dim=0)\n",
    "        self.norm = is_normalize\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if(self.norm==True):\n",
    "         x = nn.functional.normalize(self.fc3(x))\n",
    "        else:\n",
    "         x = self.fc3(x)\n",
    "         \n",
    "        # x = self.soft(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_original_mnist = './ica_reduced_network/mnist/original_network_mnist.pt'\n",
    "# original_network_mnist = torch.load(path_original_mnist)\n",
    "# original_network_mnist.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_network_mnist = NN(is_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sulta\\Jupyter NoteBooks\\Effectiveness of different dimensionality reduction techniques on pruned deep neural network\\custom_nn_ICA.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training(original_network_mnist,trainloader_mnist, validloader_mnist, \u001b[39m5\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmnist_original_network_accloss\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\sulta\\Jupyter NoteBooks\\Effectiveness of different dimensionality reduction techniques on pruned deep neural network\\custom_nn_ICA.ipynb Cell 21\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(model, trainset, valset, n, filename)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainset):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sulta/Jupyter%20NoteBooks/Effectiveness%20of%20different%20dimensionality%20reduction%20techniques%20on%20pruned%20deep%20neural%20network/custom_nn_ICA.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad(\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(original_network_mnist,trainloader_mnist, validloader_mnist, 5, 'mnist_original_network_accloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(original_network_mnist, testloader_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.2 %\n",
      "Accuracy for class: 1     is 99.5 %\n",
      "Accuracy for class: 2     is 99.0 %\n",
      "Accuracy for class: 3     is 98.6 %\n",
      "Accuracy for class: 4     is 98.8 %\n",
      "Accuracy for class: 5     is 99.2 %\n",
      "Accuracy for class: 6     is 98.7 %\n",
      "Accuracy for class: 7     is 99.5 %\n",
      "Accuracy for class: 8     is 99.5 %\n",
      "Accuracy for class: 9     is 98.1 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(original_network_mnist, testloader_mnist, classes_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(original_network_mnist, path_original_mnist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we perform dimensional reduction of the original network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_mnist_network = copy.deepcopy(original_network_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1 layer weight\n",
      "x_new vector\n",
      "torch.Size([60, 256])\n",
      "torch.Size([120, 60])\n",
      "torch.Size([84, 60])\n",
      "x_new vector\n",
      "torch.Size([42, 60])\n",
      "fc2 layer weight\n",
      "torch.Size([42, 60])\n",
      "fc3 layer weight\n",
      "torch.Size([10, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(1, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=60, bias=False)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=False)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_weight_list = drprojection(\n",
    "    original_network_mnist, dec.FastICA, 'unit-variance')\n",
    "ica_mnist_layers = (nn.Linear(256, 60, False), nn.Linear(60, 42, False), nn.Linear(42, 10, False))\n",
    "ica_mnist_network = construct_model(ica_mnist_network, ica_mnist_layers)\n",
    "ica_mnist_network = are_weights(ica_mnist_network, tuple(mnist_weight_list))\n",
    "ica_mnist_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_mnist_network, testloader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 82.1 %\n",
      "Accuracy for class: 1     is 55.4 %\n",
      "Accuracy for class: 2     is 62.6 %\n",
      "Accuracy for class: 3     is 84.6 %\n",
      "Accuracy for class: 4     is 95.6 %\n",
      "Accuracy for class: 5     is 81.4 %\n",
      "Accuracy for class: 6     is 96.7 %\n",
      "Accuracy for class: 7     is 39.4 %\n",
      "Accuracy for class: 8     is 96.5 %\n",
      "Accuracy for class: 9     is 87.2 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_mnist_network, testloader_mnist, classes_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_mnist_network = './ica_reduced_network/mnist/ica_mnist_network.pt'\n",
    "torch.save(ica_mnist_network, path_ica_mnist_network)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRAINING DR NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(1, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=60, bias=False)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=False)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_mnist_network_retrained = copy.deepcopy(ica_mnist_network)\n",
    "ica_mnist_network_retrained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2500] train loss: 0.086 train acc: 97.416 valid acc: 98.170 valid loss  0.063 \n",
      "epoch: 1\n",
      "[2,  2500] train loss: 0.043 train acc: 98.608 valid acc: 98.490 valid loss  0.050 \n",
      "epoch: 2\n",
      "[3,  2500] train loss: 0.030 train acc: 99.086 valid acc: 98.560 valid loss  0.054 \n",
      "epoch: 3\n",
      "[4,  2500] train loss: 0.025 train acc: 99.216 valid acc: 98.670 valid loss  0.063 \n",
      "epoch: 4\n",
      "[5,  2500] train loss: 0.021 train acc: 99.354 valid acc: 98.740 valid loss  0.051 \n",
      "Finished Training\n",
      "Saved dictionary of loss and accuracy!\n"
     ]
    }
   ],
   "source": [
    "training(ica_mnist_network_retrained,trainloader_mnist, validloader_mnist, 5, 'ica_accuracy_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_mnist_network_retrained, testloader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.4 %\n",
      "Accuracy for class: 1     is 99.7 %\n",
      "Accuracy for class: 2     is 99.4 %\n",
      "Accuracy for class: 3     is 99.4 %\n",
      "Accuracy for class: 4     is 99.3 %\n",
      "Accuracy for class: 5     is 98.9 %\n",
      "Accuracy for class: 6     is 96.3 %\n",
      "Accuracy for class: 7     is 99.3 %\n",
      "Accuracy for class: 8     is 99.1 %\n",
      "Accuracy for class: 9     is 97.7 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_mnist_network_retrained, testloader_mnist, classes_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_mnist_retrained = './ica_reduced_network/mnist/ica_mnist_retrained_network.pt'\n",
    "torch.save(ica_mnist_network_retrained, path_ica_mnist_retrained)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINITIALIZING SMALL NETWORK AND RETRAIING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_layer_mnist = (nn.Linear(400,60), nn.Linear(60,42), nn.Linear(42,10))\n",
    "small_network_mnist = NN(is_norm=False)\n",
    "small_network_mnist = construct_model(small_network_mnist,small_layer_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n",
      "[1,  2500] train loss: 0.261 train acc: 91.630 valid acc: 97.930 valid loss  0.067 \n",
      "epoch: 1\n",
      "[2,  2500] train loss: 0.060 train acc: 98.186 valid acc: 98.470 valid loss  0.051 \n",
      "epoch: 2\n",
      "[3,  2500] train loss: 0.043 train acc: 98.614 valid acc: 98.760 valid loss  0.044 \n",
      "epoch: 3\n",
      "[4,  2500] train loss: 0.033 train acc: 98.992 valid acc: 98.660 valid loss  0.047 \n",
      "epoch: 4\n",
      "[5,  2500] train loss: 0.027 train acc: 99.164 valid acc: 98.960 valid loss  0.037 \n",
      "Finished Training\n",
      "Saved dictionary of loss and accuracy!\n"
     ]
    }
   ],
   "source": [
    "training(small_network_mnist, trainloader_mnist,\n",
    "         validloader_mnist, 5, 'small_network_mnist_accloss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(small_network_mnist, testloader_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_small_network = './ica_reduced_network/mnist/small_mnist_network.pt'\n",
    "torch.save(small_network_mnist, path_small_network)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the original network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_original_network_mnist = copy.deepcopy(original_network_mnist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first we create a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_function(model, amount_to_prune):\n",
    "    module_lits = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module_lits.append((module, 'weight'))\n",
    "    prune.global_unstructured(\n",
    "        module_lits,\n",
    "        pruning_method=prune.RandomUnstructured,\n",
    "        amount = amount_to_prune\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform pruning by calling a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_function(pruned_original_network_mnist,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(pruned_original_network_mnist, testloader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 94.9 %\n",
      "Accuracy for class: 1     is 95.9 %\n",
      "Accuracy for class: 2     is 88.5 %\n",
      "Accuracy for class: 3     is 95.0 %\n",
      "Accuracy for class: 4     is 98.4 %\n",
      "Accuracy for class: 5     is 93.6 %\n",
      "Accuracy for class: 6     is 96.2 %\n",
      "Accuracy for class: 7     is 98.2 %\n",
      "Accuracy for class: 8     is 95.7 %\n",
      "Accuracy for class: 9     is 39.8 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(pruned_original_network_mnist, testloader_mnist, classes_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pruned_original_network_mnist = './ica_reduced_network/mnist/pruned/pruned_original_network_mnist.pt'\n",
    "torch.save(pruned_original_network_mnist,path_pruned_original_network_mnist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensional reduction and Pruning of original network mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_pruned_network_mnist = copy.deepcopy(\n",
    "    pruned_original_network_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_pruned_network_mnist, testloader_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1 layer weight\n",
      "x_new vector\n",
      "torch.Size([60, 256])\n",
      "torch.Size([120, 60])\n",
      "torch.Size([84, 60])\n",
      "x_new vector\n",
      "torch.Size([42, 60])\n",
      "fc2 layer weight\n",
      "torch.Size([42, 60])\n",
      "fc3 layer weight\n",
      "torch.Size([10, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(1, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=60, bias=False)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=False)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_weight_list_pruned = drprojection(\n",
    "    ica_pruned_network_mnist, dec.FastICA, 'unit-variance')\n",
    "ica_mnist_layers_pruned = (nn.Linear(256, 60, False), nn.Linear(\n",
    "    60, 42, False), nn.Linear(42, 10, False))\n",
    "ica_pruned_network_mnist = construct_model(\n",
    "    ica_pruned_network_mnist, ica_mnist_layers_pruned)\n",
    "ica_pruned_network_mnist = are_weights(ica_pruned_network_mnist, tuple(mnist_weight_list_pruned))\n",
    "ica_pruned_network_mnist.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 66 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_pruned_network_mnist, testloader_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 91.9 %\n",
      "Accuracy for class: 1     is 30.7 %\n",
      "Accuracy for class: 2     is 43.1 %\n",
      "Accuracy for class: 3     is 86.9 %\n",
      "Accuracy for class: 4     is 90.6 %\n",
      "Accuracy for class: 5     is 82.2 %\n",
      "Accuracy for class: 6     is 97.4 %\n",
      "Accuracy for class: 7     is 51.9 %\n",
      "Accuracy for class: 8     is 71.4 %\n",
      "Accuracy for class: 9     is 24.4 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_pruned_network_mnist, testloader_mnist, classes_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_pruned_network_mnist = './ica_reduced_network/mnist/pruned/ica_pruned_network_mnist.pt'\n",
    "torch.save(ica_pruned_network_mnist, path_ica_pruned_network_mnist)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional reduction using the data CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN2(nn.Module):\n",
    "    def __init__(self, is_norm=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=12, kernel_size=(5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=12, out_channels=16, kernel_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.soft = nn.Softmax(dim=0)\n",
    "        self.is_norm = is_norm\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if(self.is_norm == True):\n",
    "            x = nn.functional.normalize(self.fc3(x))\n",
    "        else:\n",
    "            x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cifar_original_net = './ica_reduced_network/cifar/cifar_original_net.pt'\n",
    "# cifar_original_net = torch.load(path_cifar_original_net)\n",
    "# cifar_original_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_original_net = NN2(is_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n",
      "[1,  1250] train loss: 1.694 train acc: 37.722 valid acc: 46.020 valid loss  1.467 \n",
      "epoch: 1\n",
      "[2,  1250] train loss: 1.333 train acc: 52.118 valid acc: 53.620 valid loss  1.309 \n",
      "epoch: 2\n",
      "[3,  1250] train loss: 1.180 train acc: 57.829 valid acc: 59.780 valid loss  1.178 \n",
      "epoch: 3\n",
      "[4,  1250] train loss: 1.078 train acc: 61.720 valid acc: 61.200 valid loss  1.128 \n",
      "epoch: 4\n",
      "[5,  1250] train loss: 1.006 train acc: 64.387 valid acc: 61.800 valid loss  1.097 \n",
      "epoch: 5\n",
      "[6,  1250] train loss: 0.941 train acc: 66.791 valid acc: 61.620 valid loss  1.144 \n",
      "epoch: 6\n",
      "[7,  1250] train loss: 0.890 train acc: 68.324 valid acc: 62.900 valid loss  1.095 \n",
      "epoch: 7\n",
      "[8,  1250] train loss: 0.844 train acc: 69.860 valid acc: 61.920 valid loss  1.134 \n",
      "epoch: 8\n",
      "[9,  1250] train loss: 0.808 train acc: 71.529 valid acc: 63.900 valid loss  1.103 \n",
      "epoch: 9\n",
      "[10,  1250] train loss: 0.771 train acc: 72.682 valid acc: 63.960 valid loss  1.099 \n",
      "Finished Training\n",
      "Saved dictionary of loss and accuracy!\n"
     ]
    }
   ],
   "source": [
    "training(cifar_original_net, trainloader_cifar, validloader_cifar, 10, 'cifar_original_net_accloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(cifar_original_net, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 67.1 %\n",
      "Accuracy for class: car   is 73.3 %\n",
      "Accuracy for class: bird  is 52.4 %\n",
      "Accuracy for class: cat   is 30.0 %\n",
      "Accuracy for class: deer  is 58.7 %\n",
      "Accuracy for class: dog   is 66.5 %\n",
      "Accuracy for class: frog  is 77.7 %\n",
      "Accuracy for class: horse is 66.7 %\n",
      "Accuracy for class: ship  is 76.9 %\n",
      "Accuracy for class: truck is 72.1 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(cifar_original_net, testloader_cifar, classes_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cifar_original_net, path_cifar_original_net)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensional reduction of cifar network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1 layer weight\n",
      "x_new vector\n",
      "torch.Size([60, 400])\n",
      "torch.Size([120, 60])\n",
      "torch.Size([84, 60])\n",
      "x_new vector\n",
      "torch.Size([42, 60])\n",
      "fc2 layer weight\n",
      "torch.Size([42, 60])\n",
      "fc3 layer weight\n",
      "torch.Size([10, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN2(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=60, bias=False)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=False)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_cifar_network = copy.deepcopy(cifar_original_net)\n",
    "\n",
    "cifar_weight_list = drprojection(\n",
    "    ica_cifar_network, dec.FastICA, 'unit-variance')\n",
    "\n",
    "cifar_mnist_layers = (nn.Linear(256, 60, False), nn.Linear(\n",
    "    60, 42, False), nn.Linear(42, 10, False))\n",
    "\n",
    "ica_cifar_network = construct_model(\n",
    "    ica_cifar_network, cifar_mnist_layers)\n",
    "    \n",
    "ica_cifar_network = are_weights(ica_cifar_network, tuple(cifar_weight_list))\n",
    "ica_cifar_network.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 32 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_cifar_network, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 24.7 %\n",
      "Accuracy for class: car   is 73.3 %\n",
      "Accuracy for class: bird  is 25.5 %\n",
      "Accuracy for class: cat   is 0.3 %\n",
      "Accuracy for class: deer  is 26.2 %\n",
      "Accuracy for class: dog   is 17.6 %\n",
      "Accuracy for class: frog  is 94.0 %\n",
      "Accuracy for class: horse is 6.6 %\n",
      "Accuracy for class: ship  is 38.9 %\n",
      "Accuracy for class: truck is 13.7 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_cifar_network, testloader_cifar, classes_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_cifar_network ='./ica_reduced_network/cifar/ica_cifar_network.pt'\n",
    "torch.save(ica_cifar_network, path_ica_cifar_network)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining of the ica network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_cifar_network_retrained = copy.deepcopy(ica_cifar_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1250] train loss: 1.438 train acc: 50.176 valid acc: 54.080 valid loss  1.340 \n",
      "epoch: 1\n",
      "[2,  1250] train loss: 1.200 train acc: 58.736 valid acc: 59.160 valid loss  1.187 \n",
      "epoch: 2\n",
      "[3,  1250] train loss: 1.116 train acc: 62.280 valid acc: 61.200 valid loss  1.147 \n",
      "epoch: 3\n",
      "[4,  1250] train loss: 1.061 train acc: 63.733 valid acc: 62.460 valid loss  1.119 \n",
      "epoch: 4\n",
      "[5,  1250] train loss: 1.013 train acc: 65.184 valid acc: 62.280 valid loss  1.141 \n",
      "epoch: 5\n",
      "[6,  1250] train loss: 0.983 train acc: 66.389 valid acc: 63.480 valid loss  1.121 \n",
      "epoch: 6\n",
      "[7,  1250] train loss: 0.951 train acc: 67.822 valid acc: 62.700 valid loss  1.142 \n",
      "epoch: 7\n",
      "[8,  1250] train loss: 0.921 train acc: 68.569 valid acc: 63.660 valid loss  1.139 \n",
      "epoch: 8\n",
      "[9,  1250] train loss: 0.897 train acc: 69.233 valid acc: 63.920 valid loss  1.090 \n",
      "epoch: 9\n",
      "[10,  1250] train loss: 0.879 train acc: 69.931 valid acc: 64.220 valid loss  1.107 \n",
      "Finished Training\n",
      "Saved dictionary of loss and accuracy!\n"
     ]
    }
   ],
   "source": [
    "training(ica_cifar_network_retrained, trainloader_cifar, validloader_cifar, 10, 'ica_cifar_retrained_accloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 63 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_cifar_network_retrained, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 51.0 %\n",
      "Accuracy for class: car   is 82.7 %\n",
      "Accuracy for class: bird  is 55.5 %\n",
      "Accuracy for class: cat   is 45.6 %\n",
      "Accuracy for class: deer  is 54.8 %\n",
      "Accuracy for class: dog   is 50.4 %\n",
      "Accuracy for class: frog  is 76.5 %\n",
      "Accuracy for class: horse is 66.4 %\n",
      "Accuracy for class: ship  is 75.4 %\n",
      "Accuracy for class: truck is 75.4 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_cifar_network_retrained, testloader_cifar, classes_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_cifar_network_retrained = './ica_reduced_network/cifar/ica_cifar_network_retrained.pt'\n",
    "torch.save(ica_cifar_network_retrained, path_ica_cifar_network_retrained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small cifar network training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_layer = (nn.Linear(400,60), nn.Linear(60,42), nn.Linear(42,10))\n",
    "small_network_cifar = NN2(is_norm=False)\n",
    "small_network_cifar = construct_model(small_network_cifar,small_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n",
      "[1,  1250] train loss: 1.734 train acc: 35.433 valid acc: 45.820 valid loss  1.467 \n",
      "epoch: 1\n",
      "[2,  1250] train loss: 1.345 train acc: 51.427 valid acc: 55.900 valid loss  1.231 \n",
      "epoch: 2\n",
      "[3,  1250] train loss: 1.185 train acc: 57.856 valid acc: 60.320 valid loss  1.130 \n",
      "epoch: 3\n",
      "[4,  1250] train loss: 1.081 train acc: 61.993 valid acc: 62.720 valid loss  1.079 \n",
      "epoch: 4\n",
      "[5,  1250] train loss: 1.013 train acc: 64.522 valid acc: 64.340 valid loss  1.050 \n",
      "epoch: 5\n",
      "[6,  1250] train loss: 0.953 train acc: 66.669 valid acc: 66.000 valid loss  0.991 \n",
      "epoch: 6\n",
      "[7,  1250] train loss: 0.918 train acc: 67.958 valid acc: 63.480 valid loss  1.089 \n",
      "epoch: 7\n",
      "[8,  1250] train loss: 0.885 train acc: 69.238 valid acc: 65.600 valid loss  1.018 \n",
      "epoch: 8\n",
      "[9,  1250] train loss: 0.856 train acc: 70.267 valid acc: 66.640 valid loss  0.983 \n",
      "epoch: 9\n",
      "[10,  1250] train loss: 0.831 train acc: 70.778 valid acc: 67.420 valid loss  0.990 \n",
      "Finished Training\n",
      "Saved dictionary of loss and accuracy!\n"
     ]
    }
   ],
   "source": [
    "training(small_network_cifar, trainloader_cifar, validloader_cifar, 10,'small_network_cifar_accloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(small_network_cifar, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 64.3 %\n",
      "Accuracy for class: car   is 72.2 %\n",
      "Accuracy for class: bird  is 58.3 %\n",
      "Accuracy for class: cat   is 49.0 %\n",
      "Accuracy for class: deer  is 64.7 %\n",
      "Accuracy for class: dog   is 52.1 %\n",
      "Accuracy for class: frog  is 68.6 %\n",
      "Accuracy for class: horse is 67.5 %\n",
      "Accuracy for class: ship  is 83.5 %\n",
      "Accuracy for class: truck is 68.0 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(small_network_cifar, testloader_cifar, classes_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_small_network_cifar = './ica_reduced_network/cifar/small_network_cifar.pt'\n",
    "torch.save(small_network_cifar, path_small_network_cifar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning with cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_cifar_net = copy.deepcopy(cifar_original_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_function(pruned_cifar_net, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(pruned_cifar_net, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pruned_cifar_net = './ica_reduced_network/cifar/pruned/pruned_cifar_net.pt'\n",
    "torch.save(pruned_cifar_net, path_pruned_cifar_net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensional reduction and prunning with cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1 layer weight\n",
      "x_new vector\n",
      "torch.Size([60, 400])\n",
      "torch.Size([120, 60])\n",
      "torch.Size([84, 60])\n",
      "x_new vector\n",
      "torch.Size([42, 60])\n",
      "fc2 layer weight\n",
      "torch.Size([42, 60])\n",
      "fc3 layer weight\n",
      "torch.Size([10, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN2(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=60, bias=False)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=False)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_pruned_net_cifar = copy.deepcopy(pruned_cifar_net)\n",
    "\n",
    "cifar_weight_list_pruned = drprojection(\n",
    "    ica_pruned_net_cifar, dec.FastICA, 'unit-variance')\n",
    "\n",
    "pruned_cifar_mnist_layers = (nn.Linear(256, 60, False), nn.Linear(\n",
    "    60, 42, False), nn.Linear(42, 10, False))\n",
    "\n",
    "ica_pruned_net_cifar = construct_model(\n",
    "    ica_pruned_net_cifar, pruned_cifar_mnist_layers)\n",
    "\n",
    "ica_pruned_net_cifar = are_weights(ica_pruned_net_cifar, tuple(cifar_weight_list_pruned))\n",
    "ica_pruned_net_cifar.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 36 %\n"
     ]
    }
   ],
   "source": [
    "average_accuracy(ica_pruned_net_cifar, testloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 54.9 %\n",
      "Accuracy for class: car   is 52.5 %\n",
      "Accuracy for class: bird  is 21.2 %\n",
      "Accuracy for class: cat   is 11.3 %\n",
      "Accuracy for class: deer  is 44.9 %\n",
      "Accuracy for class: dog   is 32.8 %\n",
      "Accuracy for class: frog  is 32.7 %\n",
      "Accuracy for class: horse is 10.0 %\n",
      "Accuracy for class: ship  is 33.0 %\n",
      "Accuracy for class: truck is 72.9 %\n"
     ]
    }
   ],
   "source": [
    "every_class_accuracy(ica_pruned_net_cifar, testloader_cifar, classes_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ica_pruned_net_cifar = './ica_reduced_network/cifar/pruned/ica_pruned_net_cifar.pt'\n",
    "torch.save(ica_pruned_net_cifar,path_ica_pruned_net_cifar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d3f8c5eab914c59069000d848c6aab31ffabbffb9c6caba6347117ae902c901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
