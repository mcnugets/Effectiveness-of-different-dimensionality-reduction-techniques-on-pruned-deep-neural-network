{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn as sk\n",
    "from sklearn import decomposition as dec\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=12, kernel_size=(5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=12, out_channels=16, kernel_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=5)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './cifar_net.pt'\n",
    "model = NN()\n",
    "# model.load_state_dict(torch.load(path))\n",
    "model_small = NN()\n",
    "# model_small.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 400])\n"
     ]
    }
   ],
   "source": [
    "# first layer \n",
    "fc_W = model_small.fc1.weight.detach().numpy()\n",
    "new_components = int(fc_W.shape[0]/2)\n",
    "reduction = dec.PCA(n_components=new_components, svd_solver='full')\n",
    "fc_1_reduced = reduction.fit_transform(fc_W.T)\n",
    "fc_1_reduced = torch.tensor(fc_1_reduced.T)\n",
    "print(fc_1_reduced.shape)\n",
    "\n",
    "bias_fc1 = model_small.fc1.bias\n",
    "\n",
    "# print(bias_fc1.shape)\n",
    "# bias_fc1 = bias_fc1.reshape(90, -1)\n",
    "# bias_reduction = dec.PCA(n_components=1)\n",
    "# fc1_bias_reduced = bias_reduction.fit_transform(bias_fc1.detach().numpy())\n",
    "\n",
    "# fc1_bias_reduced = torch.tensor(fc1_bias_reduced.flatten())\n",
    "# print('reduced bias:', fc1_bias_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 60])\n"
     ]
    }
   ],
   "source": [
    "#second layer \n",
    "fc2_W = model_small.fc2.weight.detach().numpy()\n",
    "PCA_fc2 = dec.PCA(n_components=new_components, svd_solver='full')\n",
    "fc2_reduced = PCA_fc2.fit_transform(fc2_W)\n",
    "\n",
    "fc2_reduced = fc2_reduced.T\n",
    "PCA2_fc2 = dec.PCA(n_components=int(fc2_reduced.shape[1]/2), svd_solver='full')\n",
    "fc2_reduced = PCA2_fc2.fit_transform(fc2_reduced)\n",
    "fc2_reduced =  torch.tensor(fc2_reduced.T)\n",
    "print(fc2_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 42)\n",
      "torch.Size([10, 42])\n"
     ]
    }
   ],
   "source": [
    "# if n_components/2 is bigger than n_features then dont transpose, but perform reshaping and reduction \n",
    "\n",
    "fc3_w = model_small.fc3.weight.detach().numpy()\n",
    "fc3_w = fc3_w.reshape([fc3_w.shape[0] * 2, -1])\n",
    "print(fc3_w.shape)\n",
    "fc3_w = fc3_w.T\n",
    "PCA_fc3 = dec.PCA(n_components=int(fc3_w.shape[1]/2), svd_solver='full')\n",
    "fc3_w_reduced = PCA_fc3.fit_transform(fc3_w)\n",
    "fc3_w_reduced = torch.tensor(fc3_w_reduced.T)\n",
    "\n",
    "print(fc3_w_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreating new network \n",
    "model_small.fc1 = nn.Linear(in_features=400, out_features=60, bias=True)\n",
    "model_small.fc1.weight = nn.Parameter(fc_1_reduced)\n",
    "# model_small.fc1.bias = nn.Parameter(fc1_bias_reduced)\n",
    "\n",
    "model_small.fc2 = nn.Linear(in_features=60, out_features=42, bias=True)\n",
    "model_small.fc2.weight = nn.Parameter(fc2_reduced)\n",
    "\n",
    "\n",
    "model_small.fc3 = nn.Linear(in_features=42, out_features=10, bias=True)\n",
    "model_small.fc3.weight = nn.Parameter(fc3_w_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=60, bias=True)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_small.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15.8766, 34.9308,  7.3381, 22.3589], grad_fn=<MaxBackward0>)\n",
      "plane\n",
      "plane\n",
      "plane\n",
      "plane\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(testloader)\n",
    "in_img, lbl = dataset.next()\n",
    "outputl = model_small(in_img)\n",
    "\n",
    "acc,temp_pred = torch.max(outputl,dim=1)\n",
    "print(acc)\n",
    "\n",
    "for a in temp_pred:\n",
    "    print(classes[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0205, 7.7926, 5.0547, 4.5317], grad_fn=<MaxBackward0>)\n",
      "cat\n",
      "ship\n",
      "plane\n",
      "plane\n"
     ]
    }
   ],
   "source": [
    "outputl = model(in_img)\n",
    "\n",
    "acc,temp_pred = torch.max(outputl,dim=1)\n",
    "print(acc)\n",
    "\n",
    "for a in temp_pred:\n",
    "    print(classes[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 42)\n",
      "fc2_layer_reduced  (42, 120)\n"
     ]
    }
   ],
   "source": [
    "#reduction of the second layer of the network \n",
    "fc2_w = model.fc2.weight.detach().numpy()\n",
    "fc2_PCA = dec.PCA(n_components=int(84/2))\n",
    "fc2_layer_reduced = fc2_PCA.fit_transform(fc2_w.T)\n",
    "print(fc2_layer_reduced.shape)\n",
    "fc2_layer_reduced = fc2_layer_reduced.T\n",
    "print('fc2_layer_reduced ', fc2_layer_reduced.shape)\n",
    "\n",
    "#perform multiplication of old matrix and reduced matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 84])\n",
      "new matrix of fc3 layer:  torch.Size([10, 42])\n",
      "torch.Size([42, 84])\n",
      "tensor([ 0.8395,  0.8469,  0.9454,  0.6472,  0.7083,  0.7650,  0.5385,  0.8060,\n",
      "         0.9144,  0.6490,  0.9273,  0.6979,  0.6682,  0.3946,  0.6890,  0.7483,\n",
      "         0.2198,  0.8316,  0.6959,  0.8775,  0.6261,  0.3385,  0.6635,  0.6180,\n",
      "         0.8512,  0.6699,  0.9532,  0.4287,  0.8352,  0.8731,  0.1903,  0.4935,\n",
      "         0.8885, -0.3047,  0.2722,  0.6279,  0.8193,  0.4788,  0.8583,  0.7888,\n",
      "         0.8218,  0.8430,  0.6485,  0.9124,  0.8887,  0.6772,  0.8583,  0.9225,\n",
      "         0.8845,  0.3520,  0.8102,  0.8137,  0.7740,  0.8066,  0.8770,  0.9296,\n",
      "         0.8875,  0.8340,  0.3671,  0.8011,  0.7058,  0.2967,  0.6892,  0.8286,\n",
      "         0.5859,  0.8805,  0.7201,  0.6430,  0.7113,  0.0725, -0.1680,  0.7011,\n",
      "         0.7720,  0.8795,  0.6934,  0.7270,  0.4572,  0.7839,  0.7352,  0.8298,\n",
      "         0.5066,  0.4515,  0.5519,  0.7777], grad_fn=<SumBackward1>)\n",
      "tensor(0.6776, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc3 = model.fc3.weight\n",
    "print(fc3.shape)\n",
    "\n",
    "new_fc3 = torch.matmul(fc3, X)\n",
    "print('new matrix of fc3 layer: ', new_fc3.shape)\n",
    "\n",
    "##conduct cosine similarity by comparing new matrix and X matrix\n",
    "\n",
    "E_temp = torch.matmul(new_fc3.T, fc3)\n",
    "print(E_temp.shape)\n",
    "\n",
    "#find similarities:\n",
    "cos_fc3 = nn.CosineSimilarity(dim=1)\n",
    "fc3_sim = cos_fc3(X, E_temp.T)\n",
    "\n",
    "print(fc3_sim)\n",
    "\n",
    "total_fc3 = 0\n",
    "\n",
    "for a in fc3_sim:\n",
    "    total_fc3 +=a\n",
    "total_fc3 = total_fc3/len(fc3_sim)\n",
    "print(total_fc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 60])\n",
      "torch.Size([60, 42])\n",
      "torch.Size([10, 42])\n",
      "----------- reduced\n",
      "torch.Size([60, 400])\n",
      "torch.Size([42, 60])\n",
      "torch.Size([10, 42])\n",
      "reasigning modified matrix to the relevant parameters:\n",
      "torch.Size([60, 400])\n",
      "torch.Size([42, 60])\n",
      "torch.Size([10, 42])\n"
     ]
    }
   ],
   "source": [
    "# reassinging the updated weight matrices to the model\n",
    "print(model.fc1.weight.shape)\n",
    "print(model.fc2.weight.shape)\n",
    "print(model.fc3.weight.shape)\n",
    "print('----------- reduced')\n",
    "\n",
    "fc_1_weight = fc_1_reduced.T\n",
    "fc_2_weight = torch.tensor(fc2_layer_reduced.T)\n",
    "\n",
    "print(fc_1_weight.shape)\n",
    "print(fc_2_weight.shape)\n",
    "print(new_fc3.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('reasigning modified matrix to the relevant parameters:')\n",
    "\n",
    "model.fc1.weight = nn.Parameter(fc_1_weight)\n",
    "model.fc2.weight = nn.Parameter(fc_2_weight)\n",
    "model.fc3.weight = nn.Parameter(new_fc3)\n",
    "\n",
    "print(model.fc1.weight.shape)\n",
    "print(model.fc2.weight.shape)\n",
    "print(model.fc3.weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84])\n",
      "torch.Size([84])\n",
      "torch.Size([42])\n"
     ]
    }
   ],
   "source": [
    "bias_fc2 = model.fc2.bias\n",
    "print(bias_fc2.shape)\n",
    "\n",
    "\n",
    "print(bias_fc2.shape)\n",
    "bias_fc2 = bias_fc2.reshape(42, -1)\n",
    "bias_fc2_reduction = dec.PCA(n_components=1)\n",
    "fc2_bias_reduced = bias_fc2_reduction.fit_transform(bias_fc2.detach().numpy())\n",
    "\n",
    "fc2_bias_reduced = torch.tensor(fc2_bias_reduced.flatten())\n",
    "print(fc2_bias_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60])\n",
      "torch.Size([42])\n"
     ]
    }
   ],
   "source": [
    "model.fc1.bias = nn.Parameter(fc1_bias_reduced)\n",
    "model.fc2.bias = nn.Parameter(fc2_bias_reduced)\n",
    "\n",
    "print(model.fc1.bias.shape)\n",
    "print(model.fc2.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "ship\n",
      "ship\n",
      "plane\n"
     ]
    }
   ],
   "source": [
    "data_batch_sample = iter(testloader)\n",
    "input, labels = data_batch_sample.next()\n",
    "\n",
    "for label in labels:\n",
    "    print(classes[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "result = model(input)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "cat\n",
      "ship\n",
      "plane\n",
      "plane\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = model(in_img)\n",
    "theloss = criterion(output, labels)\n",
    "correct = 0.0\n",
    "\n",
    "acc, lb_pred = torch.max(output, dim=1)\n",
    "\n",
    "correct += (lb_pred==labels).sum().item()\n",
    "\n",
    "accuratno = correct * 100/labels.size(0)\n",
    "print(accuratno)\n",
    "\n",
    "for a in lb_pred:\n",
    "    print(classes[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulta\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.573 acc: 46.188\n",
      "[1,  4000] loss: 1.301 acc: 54.775\n",
      "[1,  6000] loss: 1.247 acc: 56.025\n",
      "[1,  8000] loss: 1.190 acc: 58.350\n",
      "[1, 10000] loss: 1.177 acc: 58.288\n",
      "[1, 12000] loss: 1.137 acc: 60.962\n",
      "epoch: 1\n",
      "[2,  2000] loss: 1.364 acc: 62.140\n",
      "[2,  4000] loss: 1.082 acc: 61.775\n",
      "[2,  6000] loss: 1.053 acc: 63.413\n",
      "[2,  8000] loss: 1.079 acc: 61.900\n",
      "[2, 10000] loss: 1.060 acc: 63.150\n",
      "[2, 12000] loss: 1.088 acc: 62.087\n",
      "epoch: 2\n",
      "[3,  2000] loss: 1.287 acc: 64.010\n",
      "[3,  4000] loss: 1.016 acc: 64.975\n",
      "[3,  6000] loss: 1.016 acc: 64.475\n",
      "[3,  8000] loss: 0.996 acc: 65.125\n",
      "[3, 10000] loss: 1.022 acc: 64.537\n",
      "[3, 12000] loss: 0.981 acc: 65.475\n",
      "epoch: 3\n",
      "[4,  2000] loss: 1.230 acc: 65.850\n",
      "[4,  4000] loss: 0.954 acc: 66.575\n",
      "[4,  6000] loss: 0.956 acc: 66.737\n",
      "[4,  8000] loss: 0.984 acc: 66.300\n",
      "[4, 10000] loss: 0.968 acc: 66.150\n",
      "[4, 12000] loss: 0.969 acc: 66.250\n",
      "epoch: 4\n",
      "[5,  2000] loss: 1.150 acc: 67.480\n",
      "[5,  4000] loss: 0.912 acc: 68.125\n",
      "[5,  6000] loss: 0.950 acc: 66.513\n",
      "[5,  8000] loss: 0.915 acc: 67.838\n",
      "[5, 10000] loss: 0.915 acc: 68.750\n",
      "[5, 12000] loss: 0.950 acc: 67.050\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_small.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(optimizer)\n",
    "\n",
    "running_loss = 0.0\n",
    "total = 0.0\n",
    "correct = 0.0\n",
    "loss_nodr =[]\n",
    "acc_nodr = []\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    print('epoch:', epoch)\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad(True)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "             outputs = model_small(inputs).to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            loss_temp = running_loss / 2000\n",
    "            acc_temp = 100 * correct / total\n",
    "            loss_nodr.append(loss_temp)\n",
    "            acc_nodr.append(acc_temp)\n",
    "            print(\n",
    "                f'[{epoch + 1}, {i + 1:5d}] loss: {loss_temp:.3f} acc: {acc_temp:.3f}')\n",
    "            running_loss = 0.0\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8310, 6.5635, 2.8749, 4.9052], grad_fn=<MaxBackward0>)\n",
      "cat\n",
      "ship\n",
      "ship\n",
      "ship\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(testloader)\n",
    "in_img, lbl = dataset.next()\n",
    "outputl = model_small(in_img)\n",
    "\n",
    "acc, temp_pred = torch.max(outputl, dim=1)\n",
    "print(acc)\n",
    "\n",
    "for a in temp_pred:\n",
    "    print(classes[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "Accuracy of the network on the 10000 test images: 8 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "correct_1 = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs_small = model_small(images)\n",
    "        outputs_normal = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs_small.data, 1)\n",
    "        _, predicted_1 = torch.max(outputs_normal.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_1 +=(predicted_1 == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct_1 // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the reduced model pca \n",
    "new_path = './cifar_PCA_reduced.pt'\n",
    "torch.save(model_small.state_dict(),new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f8eb618b7b569c23d3b4b5bc22124c155d58b9880b777276332025b24a4c4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
